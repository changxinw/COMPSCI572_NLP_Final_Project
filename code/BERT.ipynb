{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1faba0-e3e4-4da5-bae9-db01e68b01d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from load_data import load_dataset_bert\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e364e59-09ee-4fbc-9ca6-041d568d4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self, bert, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [batch size, sent len]\n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "        #hidden = [batch size, hid dim]\n",
    "        output = self.out(hidden)\n",
    "        #output = [batch size, out dim]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d686f9f1-1878-4cf2-932c-3f0e3787575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label.long())\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label.long())\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def multi_models(model, train_iterator, valid_iterator,  test_iterator, num = 5, N_EPOCHS = 50, early_stopping = 5):\n",
    "    init_model = copy.deepcopy(model)\n",
    "    res = {}\n",
    "    res[\"test_loss\"] = []\n",
    "    res[\"test_acc\"] = []\n",
    "    ### begin training process\n",
    "    for i in range(num):\n",
    "        print('Begin training model %s'%i)\n",
    "        res[\"model_%s\"%i] = {}\n",
    "        res[\"model_%s\"%i][\"time\"] = []\n",
    "        res[\"model_%s\"%i][\"train_loss\"] = []\n",
    "        res[\"model_%s\"%i][\"val_loss\"] = []\n",
    "        res[\"model_%s\"%i][\"train_acc\"] = []\n",
    "        res[\"model_%s\"%i][\"val_acc\"] = []\n",
    "        best_valid_loss = float('inf')\n",
    "        num_steps = 0\n",
    "        ### reset model for each round\n",
    "        # model.load_state_dict(init_param)\n",
    "        model = copy.deepcopy(init_model)\n",
    "        for name, param in model.named_parameters():                \n",
    "            if name.startswith('bert'):\n",
    "                param.requires_grad = False\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion = criterion.to(device)\n",
    "        \n",
    "        for epoch in range(N_EPOCHS):\n",
    "            print('Begin epoch %s'%epoch)\n",
    "            start_time = time.time()\n",
    "            train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "            valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "            end_time = time.time()\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), 'bert-model.pt')\n",
    "                num_steps = 0\n",
    "            else:\n",
    "                num_steps += 1\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "            res[\"model_%s\"%i][\"time\"].append(end_time - start_time)\n",
    "            res[\"model_%s\"%i][\"train_loss\"].append(train_loss)\n",
    "            res[\"model_%s\"%i][\"val_loss\"].append(valid_loss)\n",
    "            res[\"model_%s\"%i][\"train_acc\"].append(train_acc)\n",
    "            res[\"model_%s\"%i][\"val_acc\"].append(valid_acc)\n",
    "            if num_steps >= early_stopping:\n",
    "                break\n",
    "        \n",
    "        model.load_state_dict(torch.load('bert-model.pt'))\n",
    "        test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "        print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "        res[\"test_loss\"].append(test_loss)\n",
    "        res[\"test_acc\"].append(test_acc)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb6b044-f739-4250-b2a6-a3fba57dbb16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training model 0\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.815 | Train Acc: 68.87%\n",
      "\t Val. Loss: 0.363 |  Val. Acc: 88.72%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.390 | Train Acc: 86.25%\n",
      "\t Val. Loss: 0.324 |  Val. Acc: 87.86%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.297 | Train Acc: 89.73%\n",
      "\t Val. Loss: 0.332 |  Val. Acc: 89.77%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.251 | Train Acc: 91.39%\n",
      "\t Val. Loss: 0.258 |  Val. Acc: 91.33%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.191 | Train Acc: 93.69%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 91.17%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.59%\n",
      "\t Val. Loss: 0.279 |  Val. Acc: 90.81%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.165 | Train Acc: 94.19%\n",
      "\t Val. Loss: 0.322 |  Val. Acc: 89.42%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.113 | Train Acc: 96.09%\n",
      "\t Val. Loss: 0.222 |  Val. Acc: 93.07%\n",
      "Begin epoch 8\n",
      "\tTrain Loss: 0.093 | Train Acc: 97.04%\n",
      "\t Val. Loss: 0.249 |  Val. Acc: 92.53%\n",
      "Begin epoch 9\n",
      "\tTrain Loss: 0.091 | Train Acc: 96.80%\n",
      "\t Val. Loss: 0.258 |  Val. Acc: 92.36%\n",
      "Begin epoch 10\n",
      "\tTrain Loss: 0.073 | Train Acc: 97.63%\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 91.16%\n",
      "Begin epoch 11\n",
      "\tTrain Loss: 0.049 | Train Acc: 98.33%\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 91.34%\n",
      "Begin epoch 12\n",
      "\tTrain Loss: 0.065 | Train Acc: 97.70%\n",
      "\t Val. Loss: 0.335 |  Val. Acc: 91.16%\n",
      "Test Loss: 0.244 | Test Acc: 93.77%\n",
      "Begin training model 1\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.847 | Train Acc: 67.50%\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 88.22%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.394 | Train Acc: 86.17%\n",
      "\t Val. Loss: 0.279 |  Val. Acc: 90.10%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.295 | Train Acc: 89.66%\n",
      "\t Val. Loss: 0.258 |  Val. Acc: 91.67%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.234 | Train Acc: 91.88%\n",
      "\t Val. Loss: 0.304 |  Val. Acc: 88.40%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.191 | Train Acc: 93.09%\n",
      "\t Val. Loss: 0.271 |  Val. Acc: 90.81%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.83%\n",
      "\t Val. Loss: 0.264 |  Val. Acc: 90.65%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.138 | Train Acc: 95.65%\n",
      "\t Val. Loss: 0.247 |  Val. Acc: 91.32%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.106 | Train Acc: 96.46%\n",
      "\t Val. Loss: 0.270 |  Val. Acc: 91.68%\n",
      "Begin epoch 8\n",
      "\tTrain Loss: 0.116 | Train Acc: 96.02%\n",
      "\t Val. Loss: 0.220 |  Val. Acc: 93.59%\n",
      "Begin epoch 9\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.32%\n",
      "\t Val. Loss: 0.280 |  Val. Acc: 92.72%\n",
      "Begin epoch 10\n",
      "\tTrain Loss: 0.062 | Train Acc: 98.01%\n",
      "\t Val. Loss: 0.258 |  Val. Acc: 92.55%\n",
      "Begin epoch 11\n",
      "\tTrain Loss: 0.053 | Train Acc: 98.31%\n",
      "\t Val. Loss: 0.302 |  Val. Acc: 92.05%\n",
      "Begin epoch 12\n",
      "\tTrain Loss: 0.061 | Train Acc: 97.96%\n",
      "\t Val. Loss: 0.253 |  Val. Acc: 93.58%\n",
      "Begin epoch 13\n",
      "\tTrain Loss: 0.041 | Train Acc: 98.56%\n",
      "\t Val. Loss: 0.390 |  Val. Acc: 91.69%\n",
      "Test Loss: 0.278 | Test Acc: 92.20%\n",
      "Begin training model 2\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.845 | Train Acc: 67.50%\n",
      "\t Val. Loss: 0.373 |  Val. Acc: 88.73%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.405 | Train Acc: 86.45%\n",
      "\t Val. Loss: 0.280 |  Val. Acc: 90.29%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.296 | Train Acc: 90.37%\n",
      "\t Val. Loss: 0.253 |  Val. Acc: 90.30%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.237 | Train Acc: 91.99%\n",
      "\t Val. Loss: 0.284 |  Val. Acc: 91.34%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.208 | Train Acc: 93.14%\n",
      "\t Val. Loss: 0.306 |  Val. Acc: 90.99%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.167 | Train Acc: 94.10%\n",
      "\t Val. Loss: 0.262 |  Val. Acc: 90.81%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.130 | Train Acc: 95.76%\n",
      "\t Val. Loss: 0.268 |  Val. Acc: 92.02%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.092 | Train Acc: 96.97%\n",
      "\t Val. Loss: 0.240 |  Val. Acc: 92.55%\n",
      "Begin epoch 8\n",
      "\tTrain Loss: 0.107 | Train Acc: 96.22%\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 90.30%\n",
      "Begin epoch 9\n",
      "\tTrain Loss: 0.079 | Train Acc: 97.30%\n",
      "\t Val. Loss: 0.293 |  Val. Acc: 91.67%\n",
      "Begin epoch 10\n",
      "\tTrain Loss: 0.081 | Train Acc: 97.30%\n",
      "\t Val. Loss: 0.334 |  Val. Acc: 90.31%\n",
      "Begin epoch 11\n",
      "\tTrain Loss: 0.064 | Train Acc: 98.07%\n",
      "\t Val. Loss: 0.265 |  Val. Acc: 91.50%\n",
      "Begin epoch 12\n",
      "\tTrain Loss: 0.061 | Train Acc: 97.89%\n",
      "\t Val. Loss: 0.268 |  Val. Acc: 91.68%\n",
      "Test Loss: 0.236 | Test Acc: 92.88%\n",
      "Begin training model 3\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.827 | Train Acc: 67.62%\n",
      "\t Val. Loss: 0.335 |  Val. Acc: 88.56%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.406 | Train Acc: 85.76%\n",
      "\t Val. Loss: 0.259 |  Val. Acc: 91.17%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.288 | Train Acc: 90.15%\n",
      "\t Val. Loss: 0.274 |  Val. Acc: 90.82%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.242 | Train Acc: 91.77%\n",
      "\t Val. Loss: 0.236 |  Val. Acc: 92.03%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.201 | Train Acc: 92.98%\n",
      "\t Val. Loss: 0.336 |  Val. Acc: 89.94%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.168 | Train Acc: 94.86%\n",
      "\t Val. Loss: 0.283 |  Val. Acc: 90.46%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.135 | Train Acc: 95.22%\n",
      "\t Val. Loss: 0.260 |  Val. Acc: 90.13%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.098 | Train Acc: 96.78%\n",
      "\t Val. Loss: 0.270 |  Val. Acc: 91.50%\n",
      "Begin epoch 8\n",
      "\tTrain Loss: 0.100 | Train Acc: 96.53%\n",
      "\t Val. Loss: 0.269 |  Val. Acc: 90.82%\n",
      "Test Loss: 0.209 | Test Acc: 94.70%\n",
      "Begin training model 4\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.812 | Train Acc: 69.17%\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 87.34%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.401 | Train Acc: 86.44%\n",
      "\t Val. Loss: 0.322 |  Val. Acc: 89.08%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.297 | Train Acc: 89.86%\n",
      "\t Val. Loss: 0.230 |  Val. Acc: 92.71%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.234 | Train Acc: 92.29%\n",
      "\t Val. Loss: 0.287 |  Val. Acc: 90.65%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.186 | Train Acc: 93.65%\n",
      "\t Val. Loss: 0.250 |  Val. Acc: 90.65%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.159 | Train Acc: 94.60%\n",
      "\t Val. Loss: 0.267 |  Val. Acc: 90.65%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.133 | Train Acc: 95.53%\n",
      "\t Val. Loss: 0.313 |  Val. Acc: 90.98%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.108 | Train Acc: 96.40%\n",
      "\t Val. Loss: 0.283 |  Val. Acc: 91.50%\n",
      "Test Loss: 0.255 | Test Acc: 91.09%\n"
     ]
    }
   ],
   "source": [
    "data_name = \"TREC\"\n",
    "train_iterator, valid_iterator, test_iterator, TEXT, LABEL = load_dataset_bert(data_name, device)\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = BERTGRUSentiment(bert, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "\n",
    "res = multi_models(model, train_iterator, valid_iterator, test_iterator)\n",
    "res[\"num_param\"] = count_parameters(model)\n",
    "with open(\"bert_%s.json\"%data_name, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b162b53f-85ec-4a64-80d0-f9f7f254865b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training model 0\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.354 | Train Acc: 84.43%\n",
      "\t Val. Loss: 0.287 |  Val. Acc: 88.04%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.278 | Train Acc: 88.40%\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 89.87%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.240 | Train Acc: 90.21%\n",
      "\t Val. Loss: 0.251 |  Val. Acc: 91.25%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.214 | Train Acc: 91.53%\n",
      "\t Val. Loss: 0.413 |  Val. Acc: 86.72%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.196 | Train Acc: 92.30%\n",
      "\t Val. Loss: 0.268 |  Val. Acc: 90.69%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.182 | Train Acc: 92.96%\n",
      "\t Val. Loss: 0.302 |  Val. Acc: 89.87%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.38%\n",
      "\t Val. Loss: 0.262 |  Val. Acc: 89.98%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.163 | Train Acc: 93.67%\n",
      "\t Val. Loss: 0.293 |  Val. Acc: 90.92%\n",
      "Test Loss: 0.239 | Test Acc: 90.33%\n",
      "Begin training model 1\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.356 | Train Acc: 84.24%\n",
      "\t Val. Loss: 0.249 |  Val. Acc: 90.40%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.276 | Train Acc: 88.46%\n",
      "\t Val. Loss: 0.249 |  Val. Acc: 90.80%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.240 | Train Acc: 90.16%\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 88.84%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.214 | Train Acc: 91.40%\n",
      "\t Val. Loss: 0.285 |  Val. Acc: 90.29%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.195 | Train Acc: 92.32%\n",
      "\t Val. Loss: 0.317 |  Val. Acc: 88.50%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.181 | Train Acc: 92.92%\n",
      "\t Val. Loss: 0.301 |  Val. Acc: 89.96%\n",
      "Test Loss: 0.252 | Test Acc: 89.78%\n",
      "Begin training model 2\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.358 | Train Acc: 84.06%\n",
      "\t Val. Loss: 0.271 |  Val. Acc: 88.95%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.275 | Train Acc: 88.40%\n",
      "\t Val. Loss: 0.290 |  Val. Acc: 89.73%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.240 | Train Acc: 90.14%\n",
      "\t Val. Loss: 0.270 |  Val. Acc: 90.69%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.213 | Train Acc: 91.50%\n",
      "\t Val. Loss: 0.274 |  Val. Acc: 88.79%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.193 | Train Acc: 92.41%\n",
      "\t Val. Loss: 0.297 |  Val. Acc: 89.89%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.179 | Train Acc: 92.99%\n",
      "\t Val. Loss: 0.290 |  Val. Acc: 90.29%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.170 | Train Acc: 93.37%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 90.45%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.159 | Train Acc: 93.82%\n",
      "\t Val. Loss: 0.323 |  Val. Acc: 89.91%\n",
      "Test Loss: 0.241 | Test Acc: 90.38%\n",
      "Begin training model 3\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.357 | Train Acc: 84.11%\n",
      "\t Val. Loss: 0.277 |  Val. Acc: 89.17%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.279 | Train Acc: 88.25%\n",
      "\t Val. Loss: 0.290 |  Val. Acc: 89.58%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.245 | Train Acc: 89.94%\n",
      "\t Val. Loss: 0.254 |  Val. Acc: 91.25%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.218 | Train Acc: 91.28%\n",
      "\t Val. Loss: 0.262 |  Val. Acc: 90.98%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.197 | Train Acc: 92.29%\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 89.42%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.183 | Train Acc: 92.71%\n",
      "\t Val. Loss: 0.257 |  Val. Acc: 90.87%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.24%\n",
      "\t Val. Loss: 0.279 |  Val. Acc: 90.20%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.165 | Train Acc: 93.59%\n",
      "\t Val. Loss: 0.326 |  Val. Acc: 88.19%\n",
      "Test Loss: 0.240 | Test Acc: 90.48%\n",
      "Begin training model 4\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.359 | Train Acc: 84.12%\n",
      "\t Val. Loss: 0.266 |  Val. Acc: 89.89%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.278 | Train Acc: 88.33%\n",
      "\t Val. Loss: 0.315 |  Val. Acc: 87.46%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.245 | Train Acc: 89.97%\n",
      "\t Val. Loss: 0.268 |  Val. Acc: 89.62%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.214 | Train Acc: 91.39%\n",
      "\t Val. Loss: 0.262 |  Val. Acc: 90.51%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.196 | Train Acc: 92.22%\n",
      "\t Val. Loss: 0.303 |  Val. Acc: 88.46%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.183 | Train Acc: 92.81%\n",
      "\t Val. Loss: 0.272 |  Val. Acc: 90.29%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.28%\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 88.06%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.162 | Train Acc: 93.72%\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 89.69%\n",
      "Begin epoch 8\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.01%\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 89.22%\n",
      "Test Loss: 0.257 | Test Acc: 90.33%\n"
     ]
    }
   ],
   "source": [
    "data_name = \"SST\"\n",
    "train_iterator, valid_iterator, test_iterator, TEXT, LABEL = load_dataset_bert(data_name, device)\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = BERTGRUSentiment(bert, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "\n",
    "res = multi_models(model, train_iterator, valid_iterator, test_iterator)\n",
    "res[\"num_param\"] = count_parameters(model)\n",
    "with open(\"bert_%s.json\"%data_name, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af473c22-76d7-456d-a77c-be1845b164f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training model 0\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.439 | Train Acc: 78.33%\n",
      "\t Val. Loss: 0.234 |  Val. Acc: 90.70%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.251 | Train Acc: 90.23%\n",
      "\t Val. Loss: 0.214 |  Val. Acc: 91.29%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.222 | Train Acc: 91.34%\n",
      "\t Val. Loss: 0.204 |  Val. Acc: 92.19%\n",
      "Begin epoch 3\n",
      "\tTrain Loss: 0.199 | Train Acc: 92.44%\n",
      "\t Val. Loss: 0.216 |  Val. Acc: 92.11%\n",
      "Begin epoch 4\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.43%\n",
      "\t Val. Loss: 0.211 |  Val. Acc: 92.70%\n",
      "Begin epoch 5\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.64%\n",
      "\t Val. Loss: 0.216 |  Val. Acc: 92.77%\n",
      "Begin epoch 6\n",
      "\tTrain Loss: 0.128 | Train Acc: 95.26%\n",
      "\t Val. Loss: 0.221 |  Val. Acc: 92.58%\n",
      "Begin epoch 7\n",
      "\tTrain Loss: 0.106 | Train Acc: 96.21%\n",
      "\t Val. Loss: 0.252 |  Val. Acc: 92.42%\n",
      "Test Loss: 0.199 | Test Acc: 92.15%\n",
      "Begin training model 1\n",
      "Begin epoch 0\n",
      "\tTrain Loss: 0.402 | Train Acc: 80.88%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 91.25%\n",
      "Begin epoch 1\n",
      "\tTrain Loss: 0.250 | Train Acc: 90.26%\n",
      "\t Val. Loss: 0.261 |  Val. Acc: 89.61%\n",
      "Begin epoch 2\n",
      "\tTrain Loss: 0.220 | Train Acc: 91.38%\n",
      "\t Val. Loss: 0.201 |  Val. Acc: 91.99%\n",
      "Begin epoch 3\n"
     ]
    }
   ],
   "source": [
    "data_name = \"IMDB\"\n",
    "train_iterator, valid_iterator, test_iterator, TEXT, LABEL = load_dataset_bert(data_name, device)\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = BERTGRUSentiment(bert, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "\n",
    "res = multi_models(model, train_iterator, valid_iterator, test_iterator)\n",
    "res[\"num_param\"] = count_parameters(model)\n",
    "with open(\"bert_%s.json\"%data_name, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481ae29-aca4-4e8f-ab2f-4a380659ce09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
